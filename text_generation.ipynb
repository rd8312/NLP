{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d131b8-4067-46a8-925d-723a1013a76b",
   "metadata": {},
   "source": [
    "# 以Transformers套件實作文字生成(Text Generation)功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee6d65e-d16f-4aaf-9a6d-d578f52395c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4022\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5245cf6c-d79f-4e33-a102-733d904aeda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "(…)ingface.co/gpt2/resolve/main/config.json: 100%|█████████████████████████████████| 665/665 [00:00<00:00, 332kB/s]\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████| 548M/548M [00:13<00:00, 41.3MB/s]\n",
      "(…)gpt2/resolve/main/generation_config.json: 100%|████████████████████████████████| 124/124 [00:00<00:00, 61.9kB/s]\n",
      "(…)gingface.co/gpt2/resolve/main/vocab.json: 100%|████████████████████████████| 1.04M/1.04M [00:00<00:00, 1.64MB/s]\n",
      "(…)gingface.co/gpt2/resolve/main/merges.txt: 100%|██████████████████████████████| 456k/456k [00:00<00:00, 5.60MB/s]\n",
      "(…)face.co/gpt2/resolve/main/tokenizer.json: 100%|████████████████████████████| 1.36M/1.36M [00:00<00:00, 6.76MB/s]\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2416ea-c719-4dc8-990a-3ac91fdb273d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'As far as I am concerned, I will be the first to admit that I am not a fan of the idea of a \"free market.\" I think that the idea of a free market is a bit of a stretch. I think that the idea'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(\"As far as I am concerned, I will\", \n",
    "                     max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3150d95d-94cc-40f7-9269-e940805bb1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"As far as I am concerned, I will have to do it. I just hope it's not for me because I don't want it to be my only option because of the way there are two very different things he and I are experiencing on Earth\"}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(\"As far as I am concerned, I will\", \n",
    "                     max_length=50, do_sample=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085b5c9-e6a4-41f3-bfc3-35da131f51fe",
   "metadata": {},
   "source": [
    "# 結合Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1c15d3-1e26-4a2b-ae6f-085f3b984c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(…)lnet-base-cased/resolve/main/config.json: 100%|█████████████████████████████████| 760/760 [00:00<00:00, 383kB/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████| 467M/467M [00:07<00:00, 66.4MB/s]\n",
      "(…)ased/resolve/main/generation_config.json: 100%|████████████████████████████████| 137/137 [00:00<00:00, 45.4kB/s]\n",
      "(…)net-base-cased/resolve/main/spiece.model: 100%|██████████████████████████████| 798k/798k [00:00<00:00, 8.07MB/s]\n",
      "(…)t-base-cased/resolve/main/tokenizer.json: 100%|████████████████████████████| 1.38M/1.38M [00:00<00:00, 5.70MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 載入相關套件\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 結合分詞器(Tokenizer)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350df543-1b47-49b4-a8a1-8d55890c4b8f",
   "metadata": {},
   "source": [
    "# 短文與提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9891880-5190-4ccf-9905-86e357b25c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 短文\n",
    "PADDING_TEXT = \"\"\"In 1991, the remains of Russian Tsar Nicholas II and his family\n",
    "(except for Alexei and Maria) are discovered.\n",
    "The voice of Nicholas's young son, Tsarevich Alexei Nikolaevich, narrates the\n",
    "remainder of the story. 1883 Western Siberia,\n",
    "a young Grigori Rasputin is asked by his father and a group of men to perform magic.\n",
    "Rasputin has a vision and denounces one of the men as a horse thief. Although his\n",
    "father initially slaps him for making such an accusation, Rasputin watches as the\n",
    "man is chased outside and beaten. Twenty years later, Rasputin sees a vision of\n",
    "the Virgin Mary, prompting him to become a priest. Rasputin quickly becomes famous,\n",
    "with people, even a bishop, begging for his blessing. <eod> </s> <eos>\"\"\"\n",
    "\n",
    "# 提示\n",
    "prompt = \"Today the weather is really nice and I am planning on \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dde6c3-a8d8-490b-99c9-5a522b33b1cf",
   "metadata": {},
   "source": [
    "# 推測答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4debb1ce-a876-464a-a893-a383a4310194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (-1). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today the weather is really nice and I am planning on flying to India for 4 weeks. I will be staying in the Bangalore-Lampin, the first part of a few weeks in India before being to India. I think that will be a great plan to go back for a few weeks before I get back. I think of it as a plan of study for three weeks, leaving the city of Bangalore and going back\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(PADDING_TEXT + prompt, add_special_tokens=False, \n",
    "                   return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "prompt_length = len(tokenizer.decode(inputs[0]))\n",
    "outputs = model.generate(inputs, max_length=250, do_sample=True, \n",
    "                         top_p=0.95, top_k=60)\n",
    "generated = prompt + tokenizer.decode(outputs[0])[prompt_length + 1 :]\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c7db7-d5ea-4cfb-ac39-60a6ccb6b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
