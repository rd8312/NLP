{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce784264-649b-4cf1-bc43-27e7affeb226",
   "metadata": {},
   "source": [
    "# 以Transformers套件實作填漏字(Masked Language Modeling)功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a704ee58-08e4-4d20-ae34-7ac5760d1ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4022\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b9ec2b-3ce2-4851-8042-4ae168a2dae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "(…)tilroberta-base/resolve/main/config.json: 100%|████████████████████████████████| 480/480 [00:00<00:00, 93.7kB/s]\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████| 331M/331M [00:05<00:00, 56.1MB/s]\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "(…)stilroberta-base/resolve/main/vocab.json: 100%|███████████████████████████████| 899k/899k [00:00<00:00, 944kB/s]\n",
      "(…)stilroberta-base/resolve/main/merges.txt: 100%|██████████████████████████████| 456k/456k [00:00<00:00, 5.78MB/s]\n",
      "(…)roberta-base/resolve/main/tokenizer.json: 100%|████████████████████████████| 1.36M/1.36M [00:00<00:00, 5.22MB/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863dee2a-dcbf-4180-a91e-fcadc11a993c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.179274782538414,\n",
      "  'sequence': 'HuggingFace is creating a tool that the community uses to solve '\n",
      "              'NLP tasks.',\n",
      "  'token': 3944,\n",
      "  'token_str': ' tool'},\n",
      " {'score': 0.11349327117204666,\n",
      "  'sequence': 'HuggingFace is creating a framework that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 7208,\n",
      "  'token_str': ' framework'},\n",
      " {'score': 0.052435003221035004,\n",
      "  'sequence': 'HuggingFace is creating a library that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 5560,\n",
      "  'token_str': ' library'},\n",
      " {'score': 0.03493543714284897,\n",
      "  'sequence': 'HuggingFace is creating a database that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 8503,\n",
      "  'token_str': ' database'},\n",
      " {'score': 0.028602207079529762,\n",
      "  'sequence': 'HuggingFace is creating a prototype that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 17715,\n",
      "  'token_str': ' prototype'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(nlp(f\"HuggingFace is creating a {nlp.tokenizer.mask_token} \" + \\\n",
    "           \"that the community uses to solve NLP tasks.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba79324-9d53-4d92-a540-fe3796d83c39",
   "metadata": {},
   "source": [
    "# 結合Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6995628c-b08e-4e7e-8487-46605bbf315e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(…)cased/resolve/main/tokenizer_config.json: 100%|██████████████████████████████| 29.0/29.0 [00:00<00:00, 14.5kB/s]\n",
      "(…)bert-base-cased/resolve/main/config.json: 100%|█████████████████████████████████| 465/465 [00:00<00:00, 233kB/s]\n",
      "(…)ilbert-base-cased/resolve/main/vocab.txt: 100%|██████████████████████████████| 213k/213k [00:00<00:00, 17.1MB/s]\n",
      "(…)t-base-cased/resolve/main/tokenizer.json: 100%|██████████████████████████████| 436k/436k [00:00<00:00, 15.3MB/s]\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████| 263M/263M [00:04<00:00, 58.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 載入相關套件\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 結合分詞器(Tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e3671-7f6b-4b34-8f23-3980400e49ba",
   "metadata": {},
   "source": [
    "# 推測答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3748df-887c-440e-8304-b4419892df32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc1e2b3-598f-4f00-9193-6d4cd4dbfa20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  {'input_ids': tensor([[  101, 12120,  2050,  8683,  1181,  3584,  1132,  2964,  1190,  1103,\n",
      "          3584,  1152, 27180,   119,  7993,  1172,  1939,  1104,  1103,  1415,\n",
      "          3827,  1156,  1494,   103,  1412,  6302,  2555, 10988,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"Distilled models are smaller than the models they mimic. \" + \\\n",
    "    f\"Using them instead of the large versions would help {tokenizer.mask_token} \" + \\\n",
    "    \"our carbon footprint.\"\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "print(\"inputs: \", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74194b69-6db6-43f4-8ba3-e09ed3e1732e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03244926-9708-497c-b3a5-0e6776a78dac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]), tensor([23]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f28b0b0-718b-4678-89f5-24e868a6cefc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.6732,  -6.6450,  -6.7923,  ...,  -5.5930,  -5.2783,  -5.6559],\n",
       "         [ -6.3221,  -5.6379,  -5.8990,  ...,  -4.6864,  -4.1499,  -5.3507],\n",
       "         [ -5.9863,  -6.0991,  -5.8089,  ...,  -5.2297,  -4.3015,  -6.5971],\n",
       "         ...,\n",
       "         [ -7.8892,  -7.6718,  -7.6357,  ...,  -6.9083,  -5.5853,  -6.2459],\n",
       "         [-14.7710, -14.2714, -14.1642,  ..., -11.4770, -12.1692, -13.1041],\n",
       "         [-14.3695, -13.9839, -13.6330,  ..., -11.2066, -11.6754, -12.7083]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(**inputs).logits\n",
    "token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db089732-7f7d-4daf-a218-9d867eef3756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 28996])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290ad31d-2ed3-4a7f-92e2-4c1bb00a9aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0972ca5-4357-4897-9d63-f7f670298555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5502, -5.6790, -5.3256,  ..., -5.4807, -4.5107, -4.2441]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3ae9a1-d743-45af-9b5e-fcd39fd9e1be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28996])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92036fd-d99a-4619-b6d6-9c8a49593620",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
