{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8559323-14b2-4997-83ec-305c08a386ea",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36cdd2-7215-4929-a663-40d69d6e4314",
   "metadata": {},
   "source": [
    "## 程式參考來源：\n",
    "- https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
    "- https://pytorch.org/text/stable/vocab.html\n",
    "- https://pytorch.org/text/stable/functional.html#to-tensor\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb81f85-95b6-47d6-870e-d8ca14da136e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4022\\anaconda3\\envs\\gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8532f3-e27e-48ef-b70b-462b777ab7b6",
   "metadata": {},
   "source": [
    "## Embedding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a059f8-9899-4631-b13d-3dc17b24ac23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[[ 0.5907, -0.8356,  1.3009,  0.0583, -0.6387],\n",
      "         [ 1.1769,  0.6917, -0.9654,  0.5125, -1.0630],\n",
      "         [-1.8748,  0.3328, -0.9192,  0.5780,  0.6709]],\n",
      "\n",
      "        [[ 0.2040, -1.3705, -2.3143, -0.8078, -0.0714],\n",
      "         [-1.1596, -0.4426, -0.1378,  0.2899,  0.0822],\n",
      "         [-1.4597,  0.1403, -1.1047, -0.1358,  1.0442]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 內含值(0~5): 為在詞彙中的索引值\n",
    "## nn.Embedding第一個參數為6，表示詞彙表含6個單字\n",
    "## nn.Embedding第二個參數為5，表示每個單字以5個實數表示\n",
    "x = torch.LongTensor([[0,1,2], [3,4,5]])\n",
    "print(x.shape)\n",
    "embeds = nn.Embedding(6, 5) \n",
    "print(embeds(x))\n",
    "print(embeds(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99653ed9-d835-4f2b-9fcd-537e29efc06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5907, -0.8356,  1.3009,  0.0583, -0.6387],\n",
       "        [ 1.1769,  0.6917, -0.9654,  0.5125, -1.0630],\n",
       "        [-1.8748,  0.3328, -0.9192,  0.5780,  0.6709],\n",
       "        [ 0.2040, -1.3705, -2.3143, -0.8078, -0.0714],\n",
       "        [-1.1596, -0.4426, -0.1378,  0.2899,  0.0822],\n",
       "        [-1.4597,  0.1403, -1.1047, -0.1358,  1.0442]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機亂數，預設為標準常態分配 N(0,1)\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa2a22a-19f9-4c67-bf56-53b5ec214bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0444,  1.8696, -0.2251, -1.5209,  0.7612],\n",
      "         [ 0.9068,  0.0946,  0.5470,  0.7086,  1.3345],\n",
      "         [-2.5969, -0.3708, -0.6219, -0.3268, -0.1398]],\n",
      "\n",
      "        [[ 1.3420, -0.7199,  0.5901,  0.5138,  0.9663],\n",
      "         [ 1.0496, -0.2049,  0.2492,  0.6211,  0.7383],\n",
      "         [ 0.3613,  0.0763, -0.2415, -1.7523, -0.7044]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[1,2,3], [4,5,6]])\n",
    "embeds = nn.Embedding(7, 5) \n",
    "print(embeds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12d175b-cd5b-4e34-a06f-95d504186a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3233, -0.1667, -2.0280,  1.0196,  0.6468],\n",
      "         [ 0.4878, -1.4289,  0.5792, -0.4249,  1.8793],\n",
      "         [-0.3445, -0.9100,  1.0745, -1.1607, -0.0575]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[-1.2572, -0.3359, -2.4758, -0.8704,  1.4450],\n",
      "         [ 0.9431,  0.2468, -1.8133,  1.6846, -0.8438]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3233, -0.1667, -2.0280,  1.0196,  0.6468],\n",
       "        [ 0.4878, -1.4289,  0.5792, -0.4249,  1.8793],\n",
       "        [-0.3445, -0.9100,  1.0745, -1.1607, -0.0575],\n",
       "        [-1.2572, -0.3359, -2.4758, -0.8704,  1.4450],\n",
       "        [ 0.9431,  0.2468, -1.8133,  1.6846, -0.8438],\n",
       "        [ 1.3610, -1.0247,  0.7604, -1.1029, -0.8650]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x2))\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a7a787-73f9-4313-92a5-7071f5c02eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5837,  0.6748,  0.0295,  0.6885,  0.9582],\n",
      "         [ 1.7321,  0.0511,  0.8235, -0.9037,  2.3132],\n",
      "         [ 1.2274,  1.0231,  1.1000,  0.6160, -0.6655]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 3, 5])\n",
      "tensor([[[ 0.1158, -1.0572,  0.9541,  0.5428,  0.3446],\n",
      "         [-0.2312,  0.6069, -0.0030,  0.8377, -1.4637]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 2, 5])\n",
      "tensor([[[ 0.1158, -1.0572,  0.9541,  0.5428,  0.3446],\n",
      "         [-0.2312,  0.6069, -0.0030,  0.8377, -1.4637]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5837,  0.6748,  0.0295,  0.6885,  0.9582],\n",
       "        [ 1.7321,  0.0511,  0.8235, -0.9037,  2.3132],\n",
       "        [ 1.2274,  1.0231,  1.1000,  0.6160, -0.6655],\n",
       "        [ 0.1158, -1.0572,  0.9541,  0.5428,  0.3446],\n",
       "        [-0.2312,  0.6069, -0.0030,  0.8377, -1.4637],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "x3 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x1).shape)\n",
    "print(embeds(x2))\n",
    "print(embeds(x2).shape)\n",
    "print(embeds(x3))\n",
    "print(embeds(x3).shape)\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4418eb6c-09e4-40c7-b4da-34193b3d8ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0467,  2.7163,  1.1429, -0.5163,  1.8922]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-1.0467,  2.7163,  1.1429, -0.5163,  1.8922],\n",
      "        [-1.5272,  0.1162,  0.4437,  1.9996,  0.6836]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 測試資料\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "# 詞彙表(vocabulary)含2個單字, 轉換為5維的向量\n",
    "embeds = nn.Embedding(2, 5) \n",
    "# 測試 hello\n",
    "lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]])\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "print(embeds.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825725d-b26c-4b85-a03c-fe9cfd5c650f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
